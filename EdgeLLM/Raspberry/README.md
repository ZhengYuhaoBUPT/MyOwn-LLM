# Run a large language model on your Raspberry Pi

From [Raspberry Pi Foundation](https://projects.raspberrypi.org/en/projects/llm-rpi/4)

We need to split the LLM in the edge. For the reason that we need Cloud-Edge collaborative, we use Docker for Kubernetes (kind) to deploy the LLM on both cloud and the edge.

## ðŸ”¹Solution: Deploy Kubernetes (Control Plane) Using Containerization on the L40

1. Running a Containerized Kubernetes Cluster (Local Isolated Environment).  

We can use kind (Kubernetes in Docker) to launch a Kubernetes cluster. Essentially, they run Kubernetes in Docker containers, isolated from the host machine and preventing contamination of the host environment.

kind is the most widely used, while k3d is more lightweight (based on k3s).

```
# Install kind
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.24.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

# Create a local cluster
kind create cluster --name mycluster
```

This will start a master node in Docker on the L40. You can verify this by running
```
kubectl get nodes
```

2. Running KubeEdge (edgecore) on edge nodes  

Since you already have KubeEdge, then run edgecore directly on the edge nodes. The key is to enable the edge nodes to connect to the cloudcore on the L40.

3. Deploy KubeEdge cloudcore in an L40 containerized Kubernetes cluster.  

Deployment can be done using keadm:

```
# Deploy cloudcore in a kind cluster
keadm init --advertise-address=<L40 public or private IP> --profile version=v1.15.0
```
Note: --advertise-address must be set to an L40 address accessible to edge nodes.

4. Join the edge node to the cloud  

On the edge node, execute:
```
keadm join --cloudcore-ipport=<L40_IP>:10000 --token=<auto-generated token>
```
If everything goes well, the edge node will be added to your kind/k3d containerized Kubernetes.
