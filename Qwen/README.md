# Qwen-7B æœ¬åœ°éƒ¨ç½²æŒ‡å—

æœ¬æ–‡æ¡£å°†æŒ‡å¯¼ä½ å¦‚ä½•åœ¨æœ¬åœ°æœåŠ¡å™¨ä¸Šéƒ¨ç½² [Qwen-7B](https://github.com/QwenLM/Qwen-7B) æ¨¡å‹ï¼Œå¹¶è¿è¡Œä¸€ä¸ªåŸºç¡€çš„ Web API æœåŠ¡ã€‚

## ğŸ“¦ ç¯å¢ƒå‡†å¤‡

```bash
# å®‰è£… Git Large File Storageï¼ˆç”¨äºæ‹‰å–å¤§æ¨¡å‹æƒé‡ï¼‰
# å¦‚æœä½ è¿˜æœªå®‰è£… git-lfsï¼Œè¯·æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š
sudo apt update
sudo apt install git-lfs -y

# åˆå§‹åŒ– git-lfs
git lfs install
```

## ğŸ§± å¯åŠ¨ tmux ä¼šè¯ï¼ˆå¯é€‰ï¼‰

```bash
# æ¨èåœ¨ tmux ä¸‹è¿è¡Œï¼Œé¿å…ä¸­æ–­
tmux
```

## ğŸ”„ å…‹éš†æ¨¡å‹ä»£ç å’Œæƒé‡

```bash
# å…‹éš† Qwen-7B æ¨¡å‹ä»£ç 
git clone https://github.com/QwenLM/Qwen-7B.git

# ä» ModelScope å…‹éš† Qwen-7B-Chat æƒé‡ï¼ˆåŒ…å« tokenizer ç­‰é…ç½®ï¼‰
git clone https://www.modelscope.cn/qwen/Qwen-7B-Chat.git qwen-7b-chat
```

## ğŸ“¦ å®‰è£…ä¾èµ–

```bash
# å®‰è£… Qwen-7B æ¨¡å‹æ‰€éœ€çš„ä¾èµ–
pip install -r ~/Qwen-7B/requirements.txt

# å®‰è£… Qwen-7B-Chat çš„é¢å¤–ä¾èµ–
pip install -r ~/qwen-7b-chat/requirements.txt
```

âš ï¸ å®‰è£…è¾ƒæ…¢æ—¶å»ºè®®ä½¿ç”¨å›½å†…é•œåƒï¼š

```bash
# ä½¿ç”¨é˜¿é‡Œäº‘é•œåƒåŠ é€Ÿ
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple
```

## ğŸš€ å¯åŠ¨ Web æœåŠ¡

```bash
# å¯åŠ¨ web_demo.pyï¼ŒæŒ‡å®šæ¨¡å‹æƒé‡è·¯å¾„å’Œç›‘å¬åœ°å€
cd ~/Qwen-7B
python web_demo.py -c ../qwen-7b-chat --server-name 0.0.0.0 --server-port 7860
```

å¯åŠ¨æˆåŠŸåï¼ŒWeb API ä¼šè¿è¡Œåœ¨ï¼š

```
http://<ä½ çš„æœåŠ¡å™¨IP>:7860
```

è‹¥ä¸æƒ³ä½¿ç”¨webï¼Œå¯ä»¥ç›´æ¥åœ¨å‘½ä»¤è¡Œç©qwen-7b-chatï¼š
```bash
wget https://raw.githubusercontent.com/ZhengYuhaoBUPT/MyOwn-LLM/main/Qwen/cli_demo.py
python cli_demo.py
```

---

## âœ… å¸¸è§é—®é¢˜

- **git lfs ä¸æ˜¯å‘½ä»¤ï¼Ÿ**
  > è¯·ç¡®ä¿æ‰§è¡Œäº† `sudo apt install git-lfs`ï¼Œå¹¶å†æ¬¡è¿è¡Œ `git lfs install`ã€‚

- **ä¾èµ–å®‰è£…å¤ªæ…¢ï¼Ÿ**
  > ä½¿ç”¨å›½å†…é•œåƒæºï¼Œä¾‹å¦‚æ¸…åæˆ–é˜¿é‡Œäº‘é•œåƒï¼Œå¯å¤§å¹…æå‡é€Ÿåº¦ã€‚

---

## ğŸ§  æ³¨æ„äº‹é¡¹

- é»˜è®¤æ¨¡å‹ä¸º Qwen-7Bï¼Œéƒ¨ç½²æ—¶éœ€é¢„ç•™çº¦ 16GB GPU æ˜¾å­˜ã€‚
- è‹¥ä½¿ç”¨ CPU æˆ–ä½æ˜¾å­˜ GPUï¼Œè¯·ä½¿ç”¨ `--cpu-only` å‚æ•°æˆ–å°è¯•é‡åŒ–æ¨¡å‹ã€‚

---

## ğŸ¤ª æ‹‰å–Qwençš„Pythonè¿è¡Œç¨‹åº

```bash
wget https://raw.githubusercontent.com/ZhengYuhaoBUPT/MyOwn-LLM/main/Qwen/StartQwen.py
```
- ä¹Ÿå¯ä»¥ä½¿ç”¨batchæ¨ç†åŠ é€Ÿ
```bash
wget https://raw.githubusercontent.com/ZhengYuhaoBUPT/MyOwn-LLM/main/Qwen/Batch_Inference.py
```

---

## é‡åŒ–

- é¦–å…ˆå®‰è£…é‡åŒ–åŒ…
pip install auto-gptq optimum
- ä»modelscopeä¸‹è½½Qwençš„Int4é‡åŒ–æ¨¡å‹
git clone https://www.modelscope.cn/Qwen/Qwen-7B-Chat-Int4.git

- ä¿®æ”¹ä¹‹å‰çš„å¯åŠ¨ä»£ç 
```bash
model = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen-7B-Chat-Int4",
    device_map="auto",
    trust_remote_code=True
).eval()
response, history = model.chat(tokenizer, "Hi", history=None)
```

- å¯ä»¥ç›´æ¥ç”¨åœ¨githubä¸­ä¿®æ”¹çš„ç‰ˆæœ¬
```bash
wget https://raw.githubusercontent.com/ZhengYuhaoBUPT/MyOwn-LLM/main/Qwen/GPTQ_Batch_Inference.py
```

- æ³¨æ„ç‰ˆæœ¬è¦æ±‚
> torch==2.1 auto-gptq>=0.5.1 transformers>=4.35.0 optimum>=1.14.0 peft>=0.6.1
torch>=2.0,<2.1 auto-gptq<0.5.0 transformers<4.35.0 optimum<1.14.0 peft>=0.5.0,<0.6.0
---

## FastAPI
- ä½¿ç”¨FastAPIï¼š
```bash
wget https://raw.githubusercontent.com/ZhengYuhaoBUPT/MyOwn-LLM/main/Qwen/qwen_fastapi
cd qwen_fastapi
uvicorn app:app --host 0.0.0.0 --port 8008
```

## å¾®è°ƒ
- ä½¿ç”¨LoRAå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œé‡‡ç”¨çš„æ•°æ®æ˜¯question_data.jsonï¼Œä¸å«æ˜Ÿè¾¹ç¼˜è®¡ç®—å’Œè¾¹ç¼˜æ¨ç†ç›¸å…³çš„å†…å®¹
```bash
wget https://raw.githubusercontent.com/ZhengYuhaoBUPT/MyOwn-LLM/main/Qwen/question_data.json
cd finetune
wget https://raw.githubusercontent.com/ZhengYuhaoBUPT/MyOwn-LLM/main/Qwen/finetune_lora_single_gpu.sh
bash finetune/finetune_lora_single_gpu.sh
```
- å¾®è°ƒç»“æŸå°±å¯ä»¥è·å¾—output_qwenæ–‡ä»¶å¤¹
```bash
# åŠ è½½å¾®è°ƒchat
wget https://raw.githubusercontent.com/ZhengYuhaoBUPT/MyOwn-LLM/main/Qwen/lora_cli_demo.json
python lora_cli_demo.json
```

- æœªç»è¿‡å¾®è°ƒçš„å›ç­”ï¼š
- å›ç­”ä¸€ï¼š
>User: ä»€ä¹ˆæ˜¯å«æ˜Ÿè¾¹ç¼˜è®¡ç®—ï¼Ÿ  
>Qwen-Chat: å«æ˜Ÿè¾¹ç¼˜è®¡ç®—æ˜¯ä¸€ç§æ–°å…´çš„æŠ€æœ¯ï¼Œå®ƒå°†è®¡ç®—èƒ½åŠ›æ”¾åœ¨å«æ˜Ÿä¸Šï¼Œä»¥æä¾›å®æ—¶çš„å¤„ç†èƒ½åŠ›ã€‚å®ƒå¯ä»¥å¸®åŠ©ç”¨æˆ·æ›´å¿«åœ°å¤„ç†æ•°æ®ï¼Œå¹¶å¯ä»¥æé«˜ç³»ç»Ÿæ•ˆç‡å’Œå®‰å…¨æ€§ã€‚å®ƒè¿˜å¯ä»¥å¸®åŠ©ç”¨æˆ·åœ¨å¤šä¸ªä½ç½®è®¿é—®å®æ—¶ä¿¡æ¯ï¼Œä»è€ŒèŠ‚çœæ—¶é—´å’Œèµ„æºã€‚   
>å¾®è°ƒåï¼šå«æ˜Ÿè¾¹ç¼˜è®¡ç®—æ˜¯æŒ‡å°†è®¡ç®—ä»»åŠ¡å’Œæ•°æ®å¤„ç†èƒ½åŠ›éƒ¨ç½²åˆ°è·ç¦»ç”¨æˆ·è¾ƒè¿‘çš„å«æ˜Ÿä¸Šï¼Œä»¥ä¾¿èƒ½å¤Ÿæ›´å¿«åœ°å“åº”ç”¨æˆ·çš„è¯·æ±‚ã€‚å®ƒå¯ä»¥å‡å°‘é€šä¿¡å»¶è¿Ÿï¼Œå¹¶æé«˜ç³»ç»Ÿå¯é æ€§ã€å¯é æ€§å’Œå¯ç”¨æ€§ã€‚   
>æˆ‘ä»¬ç»™çš„ç­”æ¡ˆï¼šå«æ˜Ÿè¾¹ç¼˜è®¡ç®—æ˜¯æŒ‡å°†è®¡ç®—èƒ½åŠ›éƒ¨ç½²åœ¨å«æ˜Ÿä¸Šï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å¤ªç©ºä¸­å°±åœ°å¤„ç†æ•°æ®ï¼Œå‡å°‘åœ°é¢ä¼ è¾“å»¶è¿Ÿã€‚

- å›ç­”äºŒï¼š
>User: è¾¹ç¼˜æ¨ç†åœ¨å«æ˜Ÿä¸Šçš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ   
>Qwen-Chat: è¾¹ç¼˜æ¨ç†åœ¨å«æ˜Ÿä¸Šä¸»è¦ç”¨äºè¯†åˆ«å’Œåˆ†æä¼ æ„Ÿå™¨é‡‡é›†çš„æ•°æ®ã€‚å®ƒå¯ä»¥å®ç°å®æ—¶åˆ†æï¼Œä¸ºç”¨æˆ·æä¾›æ›´å‡†ç¡®ã€å¯é çš„å†³ç­–æ”¯æŒã€‚æ­¤å¤–ï¼Œè¾¹ç¼˜æ¨ç†è¿˜å¯ä»¥å‡å°‘ç½‘ç»œä¼ è¾“å»¶è¿Ÿï¼ŒåŠ å¿«å¤„ç†é€Ÿåº¦ï¼Œå¹¶é™ä½å­˜å‚¨æˆæœ¬ã€‚   
>å¾®è°ƒåï¼šè¾¹ç¼˜æ¨ç†å¯ä»¥å°†åŸå§‹æ•°æ®åœ¨å«æ˜Ÿä¸Šè¿›è¡Œå®æ—¶å¤„ç†ï¼Œä»è€Œå®ç°æ•°æ®å¿«é€Ÿåˆ†æï¼Œä¸ºç”¨æˆ·æä¾›æ›´åŠ å¿«é€Ÿçš„æœåŠ¡ã€‚æ­¤å¤–ï¼Œå®ƒè¿˜å¯ä»¥å¸®åŠ©æå‡å«æ˜Ÿç³»ç»Ÿæ•´ä½“æ€§èƒ½ï¼Œé™ä½åŠŸè€—ï¼Œå‡è½»ç½‘ç»œä¼ è¾“è´Ÿæ‹…ç­‰ã€‚   
>æˆ‘ä»¬ç»™çš„ç­”æ¡ˆï¼šè¾¹ç¼˜æ¨ç†å¯ä»¥åœ¨å«æ˜Ÿæœ¬åœ°å¿«é€Ÿå¤„ç†å›¾åƒã€è§†é¢‘ç­‰ä»»åŠ¡ï¼Œå®ç°æ™ºèƒ½é¢„è­¦ã€ç›®æ ‡è¯†åˆ«ç­‰åŠŸèƒ½ï¼Œæå‡å“åº”é€Ÿåº¦å¹¶èŠ‚çœå¸¦å®½ã€‚  


## ğŸ“š å‚è€ƒ

- [Qwen-7B GitHub](https://github.com/QwenLM/Qwen-7B)
- [Qwen-7B ModelScope æƒé‡](https://modelscope.cn/models/qwen/Qwen-7B-Chat/summary)
