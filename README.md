# ğŸ§  MyOwn-LLM: Local Multi-Model Deployment & Inference Platform

ğŸ“ **MyOwn-LLM** is an experimental platform designed for local deployment and service integration of multiple open-source large language models (LLMs). It aims to explore the inference performance, API service design, and edge adaptation capabilities of LLMs for Chinese semantic tasks.

---

## ğŸš€ Supported Models

| Model Name        | Parameters | Source/Architecture   | Inference Framework         | Status      |
|------------------|------------|------------------------|-----------------------------|-------------|
| Qwen-7B           | 7B         | Alibaba Qwen           | HuggingFace + Transformers | âœ… Deployed  |
| ChatGLM3-6B       | 6B         | Tsinghua Zhipu         | HuggingFace + PEFT         | ğŸŸ¡ Planned   |
| LLaMA2-7B         | 7B         | Meta + Chinese Tuning  | PEFT + LoRA                | ğŸŸ¡ Planned   |
| Baichuan2-13B     | 13B        | Baichuan AI            | Distributed Deployment Exp. | ğŸ”² Untested |
| InternLM-Chat-7B  | 7B         | Shanghai AI Lab        | ğŸ¤– Multi-turn Dialog Exp.   | ğŸ”² Pending   |

---

## ğŸ§  Project Goals

- âœ… Rapid deployment & local inference of multiple Chinese LLMs;
- âœ… Unified API interface for different models to improve scalability;
- âœ… Exploration of lightweight tuning (LoRA, quantization) under various tasks;
- âœ… Support for model performance benchmarking (latency, accuracy, memory usage);
- â“ Evaluate feasibility of edge/low-resource deployment (e.g., satellite-edge computing);

---

## ğŸ§ª Use Cases

- ğŸ’¬ Chinese question-answering systems
- ğŸ“ Intelligent summarization & rewriting
- ğŸ¤– Multi-turn dialog construction
- ğŸ”’ Private local deployment & secure Q&A
- ğŸ“¡ Edge/satellite device deployment experiments

---

## ğŸ“Œ Example Usage

For usage instructions of each model, refer to the corresponding subdirectory `README.md`. For example:

- [Qwen-7B Instructions](./Qwen/README.md)
- [ChatGLM3-6B Instructions](./chatglm3-6b/README.md) *(in progress)*

---

## ğŸ“ˆ Planned Model Performance Comparison

| Model     | GPU Inference Time (s) | CPU Inference Time (s) | VRAM Usage | Multi-turn Dialog | Fine-tuning Support |
|-----------|------------------------|-------------------------|------------|-------------------|---------------------|
| Qwen-7B   | âœ… Fast                 | âš ï¸ Slow                 | 16 GB      | âœ… Supported       | âœ… LoRA             |
| ChatGLM3  | ğŸ”² TBD                 | ğŸ”² TBD                 | ğŸ”² TBD      | ğŸ”² TBD            | ğŸ”² TBD              |
| LLaMA2    | ğŸ”² TBD                 | ğŸ”² TBD                 | ğŸ”² TBD      | ğŸ”² TBD            | âœ… PEFT             |

---

## ğŸ“Œ TODO Features

- [x] Qwen-7B Inference API Deployment (FastAPI)
- [ ] ChatGLM3 Integration & Evaluation
- [ ] Unified LoRA Fine-tuning Pipeline
- [ ] Gradio / Web UI Integration
- [ ] Model Performance Benchmarking Module
- [ ] Logging System & Multi-user Support
- [ ] LangChain Integration (Agent-based)

---

## ğŸ‘¨â€ğŸ’» Author

**Yuhao Zheng**  
M.Sc. in Information and Communication Engineering, Beijing University of Posts and Telecommunications (BUPT)  
Research Interests: Edge Computing, Satellite Networks, Large Language Model Applications  
ğŸ“« yuhao_zheng@bupt.edu.cn  
ğŸŒ [GitHub](https://github.com/ZhengYuhaoBUPT)
